Args in experiment:
Namespace(activation='gelu', batch_size=32, c_out=7, checkpoints='./checkpoints/', conv_channel=32, d_ff=32, d_layers=1, d_model=16, data='ETTh1', data_path='ETTh1.csv', dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.1, e_layers=1, embed='timeF', embed_type=0, enc_in=7, factor=3, features='M', freq='h', gcn_depth=2, gcn_dropout=0.3, gpu=0, individual=False, is_training=1, itr=1, label_len=48, learning_rate=0.0001, loss='MSE', lradj='type1', model='MSGNet', model_id='ETTh1_96_720', moving_avg=25, n_heads=8, node_dim=10, num_kernels=6, num_nodes=7, num_workers=8, output_attention=False, patience=3, pred_len=720, propalpha=0.3, root_path='./dataset/', seasonal_patterns='Monthly', seq_len=96, skip_channel=32, subgraph_size=3, tanhalpha=3, target='OT', task_name='long_term_forecast', test_flop=False, top_k=3, train_epochs=10, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh1_96_720_MSGNet_ETTh1_ftM_sl96_ll48_pl720_dm16_nh8_el1_dl1_df32_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7825
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.6949242
	speed: 0.0506s/iter; left time: 118.4686s
	iters: 200, epoch: 1 | loss: 0.7116193
	speed: 0.0409s/iter; left time: 91.6496s
Epoch: 1 cost time: 11.1584312915802
Epoch: 1, Steps: 244 | Train Loss: 0.7255434 Vali Loss: 1.6546592 Test Loss: 0.5348536
Validation loss decreased (inf --> 1.654659).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6315065
	speed: 0.1102s/iter; left time: 231.1542s
	iters: 200, epoch: 2 | loss: 0.6741800
	speed: 0.0431s/iter; left time: 86.1166s
Epoch: 2 cost time: 11.15457034111023
Epoch: 2, Steps: 244 | Train Loss: 0.6451074 Vali Loss: 1.6093457 Test Loss: 0.4971661
Validation loss decreased (1.654659 --> 1.609346).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5205867
	speed: 0.1080s/iter; left time: 200.1035s
	iters: 200, epoch: 3 | loss: 0.5586048
	speed: 0.0441s/iter; left time: 77.3947s
Epoch: 3 cost time: 11.509177446365356
Epoch: 3, Steps: 244 | Train Loss: 0.6184086 Vali Loss: 1.5893290 Test Loss: 0.4910890
Validation loss decreased (1.609346 --> 1.589329).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5572544
	speed: 0.1116s/iter; left time: 179.6268s
	iters: 200, epoch: 4 | loss: 0.5516144
	speed: 0.0420s/iter; left time: 63.3306s
Epoch: 4 cost time: 11.365684986114502
Epoch: 4, Steps: 244 | Train Loss: 0.6010427 Vali Loss: 1.5891296 Test Loss: 0.4953369
Validation loss decreased (1.589329 --> 1.589130).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.7008876
	speed: 0.1127s/iter; left time: 153.8202s
	iters: 200, epoch: 5 | loss: 0.5955228
	speed: 0.0386s/iter; left time: 48.8129s
Epoch: 5 cost time: 10.807360887527466
Epoch: 5, Steps: 244 | Train Loss: 0.5922619 Vali Loss: 1.5918106 Test Loss: 0.4914489
EarlyStopping counter: 1 out of 3
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5245407
	speed: 0.1099s/iter; left time: 123.2308s
	iters: 200, epoch: 6 | loss: 0.6203307
	speed: 0.0402s/iter; left time: 41.0114s
Epoch: 6 cost time: 10.997309684753418
Epoch: 6, Steps: 244 | Train Loss: 0.5881829 Vali Loss: 1.5919361 Test Loss: 0.4948548
EarlyStopping counter: 2 out of 3
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5369974
	speed: 0.1115s/iter; left time: 97.7580s
	iters: 200, epoch: 7 | loss: 0.5905088
	speed: 0.0416s/iter; left time: 32.3291s
Epoch: 7 cost time: 11.304513692855835
Epoch: 7, Steps: 244 | Train Loss: 0.5865522 Vali Loss: 1.5917476 Test Loss: 0.4958936
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTh1_96_720_MSGNet_ETTh1_ftM_sl96_ll48_pl720_dm16_nh8_el1_dl1_df32_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
preds_shape: (67, 32, 720, 7)
trues_shape: (67, 32, 720, 7)
nd:0.6108912825584412, nrmse:0.8782426714897156, mse:0.49533700942993164, mae:0.4895530641078949, rse:0.6741049885749817, mape:11.295409202575684
time: 117.23231768608093
