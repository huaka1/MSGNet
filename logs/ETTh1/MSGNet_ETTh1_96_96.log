Args in experiment:
Namespace(activation='gelu', batch_size=32, c_out=7, checkpoints='./checkpoints/', conv_channel=32, d_ff=64, d_layers=1, d_model=32, data='ETTh1', data_path='ETTh1.csv', dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.1, e_layers=1, embed='timeF', embed_type=0, enc_in=7, factor=3, features='M', freq='h', gcn_depth=2, gcn_dropout=0.3, gpu=0, individual=False, is_training=1, itr=1, label_len=48, learning_rate=0.0001, loss='MSE', lradj='type1', model='MSGNet', model_id='ETTh1_96_96', moving_avg=25, n_heads=8, node_dim=10, num_kernels=6, num_nodes=7, num_workers=8, output_attention=False, patience=3, pred_len=96, propalpha=0.3, root_path='./dataset/', seasonal_patterns='Monthly', seq_len=96, skip_channel=32, subgraph_size=3, tanhalpha=3, target='OT', task_name='long_term_forecast', test_flop=False, top_k=3, train_epochs=10, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh1_96_96_MSGNet_ETTh1_ftM_sl96_ll48_pl96_dm32_nh8_el1_dl1_df64_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8449
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.5414960
	speed: 0.0801s/iter; left time: 203.5316s
	iters: 200, epoch: 1 | loss: 0.3909957
	speed: 0.0695s/iter; left time: 169.5446s
Epoch: 1 cost time: 20.31015110015869
Epoch: 1, Steps: 264 | Train Loss: 0.4646690 Vali Loss: 0.7984449 Test Loss: 0.4272026
Validation loss decreased (inf --> 0.798445).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.3567055
	speed: 0.2211s/iter; left time: 503.4270s
	iters: 200, epoch: 2 | loss: 0.3665866
	speed: 0.0651s/iter; left time: 141.7288s
Epoch: 2 cost time: 19.722734451293945
Epoch: 2, Steps: 264 | Train Loss: 0.3849676 Vali Loss: 0.7411568 Test Loss: 0.3987006
Validation loss decreased (0.798445 --> 0.741157).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.3635135
	speed: 0.2296s/iter; left time: 462.2852s
	iters: 200, epoch: 3 | loss: 0.3379740
	speed: 0.0647s/iter; left time: 123.6780s
Epoch: 3 cost time: 19.34839940071106
Epoch: 3, Steps: 264 | Train Loss: 0.3653550 Vali Loss: 0.7281134 Test Loss: 0.3962811
Validation loss decreased (0.741157 --> 0.728113).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.3237112
	speed: 0.2248s/iter; left time: 393.1603s
	iters: 200, epoch: 4 | loss: 0.3416313
	speed: 0.0634s/iter; left time: 104.6178s
Epoch: 4 cost time: 19.815868377685547
Epoch: 4, Steps: 264 | Train Loss: 0.3572905 Vali Loss: 0.7252941 Test Loss: 0.3930115
Validation loss decreased (0.728113 --> 0.725294).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.3622649
	speed: 2.0188s/iter; left time: 2997.9402s
	iters: 200, epoch: 5 | loss: 0.3710396
	speed: 0.0661s/iter; left time: 91.6176s
Epoch: 5 cost time: 194.88795590400696
Epoch: 5, Steps: 264 | Train Loss: 0.3540109 Vali Loss: 0.7245692 Test Loss: 0.3934413
Validation loss decreased (0.725294 --> 0.724569).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.4168643
	speed: 1.8166s/iter; left time: 2218.0502s
	iters: 200, epoch: 6 | loss: 0.3230822
	speed: 0.0657s/iter; left time: 73.6063s
Epoch: 6 cost time: 19.394328117370605
Epoch: 6, Steps: 264 | Train Loss: 0.3520980 Vali Loss: 0.7242185 Test Loss: 0.3924188
Validation loss decreased (0.724569 --> 0.724218).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.3242202
	speed: 0.2158s/iter; left time: 206.5329s
	iters: 200, epoch: 7 | loss: 0.3995704
	speed: 0.0614s/iter; left time: 52.6568s
Epoch: 7 cost time: 19.70559573173523
Epoch: 7, Steps: 264 | Train Loss: 0.3516326 Vali Loss: 0.7241088 Test Loss: 0.3928469
Validation loss decreased (0.724218 --> 0.724109).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.3094463
	speed: 0.2614s/iter; left time: 181.1292s
	iters: 200, epoch: 8 | loss: 0.4066745
	speed: 0.0659s/iter; left time: 39.0769s
Epoch: 8 cost time: 23.332653522491455
Epoch: 8, Steps: 264 | Train Loss: 0.3507450 Vali Loss: 0.7234383 Test Loss: 0.3928835
Validation loss decreased (0.724109 --> 0.723438).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.3248110
	speed: 0.6773s/iter; left time: 290.5758s
	iters: 200, epoch: 9 | loss: 0.3728476
	speed: 0.0667s/iter; left time: 21.9334s
Epoch: 9 cost time: 66.33543229103088
Epoch: 9, Steps: 264 | Train Loss: 0.3508115 Vali Loss: 0.7239943 Test Loss: 0.3928909
EarlyStopping counter: 1 out of 3
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.3144008
	speed: 0.2038s/iter; left time: 33.6229s
	iters: 200, epoch: 10 | loss: 0.3466980
	speed: 0.0601s/iter; left time: 3.9047s
Epoch: 10 cost time: 18.492237329483032
Epoch: 10, Steps: 264 | Train Loss: 0.3506861 Vali Loss: 0.7238867 Test Loss: 0.3928661
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.953125e-07
>>>>>>>testing : ETTh1_96_96_MSGNet_ETTh1_ftM_sl96_ll48_pl96_dm32_nh8_el1_dl1_df64_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
preds_shape: (87, 32, 96, 7)
trues_shape: (87, 32, 96, 7)
nd:0.5188425779342651, nrmse:0.7874566316604614, mse:0.3928834795951843, mae:0.4129912257194519, rse:0.5953682065010071, mape:10.380105018615723
time: 686.5907707214355
