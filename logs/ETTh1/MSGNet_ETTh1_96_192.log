Args in experiment:
Namespace(activation='gelu', batch_size=32, c_out=7, checkpoints='./checkpoints/', conv_channel=32, d_ff=64, d_layers=1, d_model=32, data='ETTh1', data_path='ETTh1.csv', dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.1, e_layers=1, embed='timeF', embed_type=0, enc_in=7, factor=3, features='M', freq='h', gcn_depth=2, gcn_dropout=0.3, gpu=0, individual=False, is_training=1, itr=1, label_len=48, learning_rate=0.0001, loss='MSE', lradj='type1', model='MSGNet', model_id='ETTh1_96_192', moving_avg=25, n_heads=8, node_dim=10, num_kernels=6, num_nodes=7, num_workers=8, output_attention=False, patience=3, pred_len=192, propalpha=0.3, root_path='./dataset/', seasonal_patterns='Monthly', seq_len=96, skip_channel=32, subgraph_size=3, tanhalpha=3, target='OT', task_name='long_term_forecast', test_flop=False, top_k=3, train_epochs=10, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh1_96_192_MSGNet_ETTh1_ftM_sl96_ll48_pl192_dm32_nh8_el1_dl1_df64_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8353
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 0.6368892
	speed: 0.0796s/iter; left time: 199.8476s
	iters: 200, epoch: 1 | loss: 0.5074374
	speed: 0.0604s/iter; left time: 145.5826s
Epoch: 1 cost time: 17.961456537246704
Epoch: 1, Steps: 261 | Train Loss: 0.5260997 Vali Loss: 1.0940064 Test Loss: 0.4820434
Validation loss decreased (inf --> 1.094006).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.4127402
	speed: 0.1743s/iter; left time: 392.2472s
	iters: 200, epoch: 2 | loss: 0.4304677
	speed: 0.0665s/iter; left time: 143.0405s
Epoch: 2 cost time: 18.76411747932434
Epoch: 2, Steps: 261 | Train Loss: 0.4543411 Vali Loss: 1.0349884 Test Loss: 0.4468512
Validation loss decreased (1.094006 --> 1.034988).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.3967151
	speed: 0.1673s/iter; left time: 332.7760s
	iters: 200, epoch: 3 | loss: 0.4690769
	speed: 0.0565s/iter; left time: 106.7743s
Epoch: 3 cost time: 16.58657717704773
Epoch: 3, Steps: 261 | Train Loss: 0.4344412 Vali Loss: 1.0221716 Test Loss: 0.4440677
Validation loss decreased (1.034988 --> 1.022172).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.4728044
	speed: 0.1688s/iter; left time: 291.7720s
	iters: 200, epoch: 4 | loss: 0.4313329
	speed: 0.0621s/iter; left time: 101.1131s
Epoch: 4 cost time: 17.7871732711792
Epoch: 4, Steps: 261 | Train Loss: 0.4248716 Vali Loss: 1.0161393 Test Loss: 0.4448085
Validation loss decreased (1.022172 --> 1.016139).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.4017051
	speed: 0.1654s/iter; left time: 242.6602s
	iters: 200, epoch: 5 | loss: 0.3758663
	speed: 0.0569s/iter; left time: 77.7533s
Epoch: 5 cost time: 16.693833112716675
Epoch: 5, Steps: 261 | Train Loss: 0.4198121 Vali Loss: 1.0142963 Test Loss: 0.4462512
Validation loss decreased (1.016139 --> 1.014296).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.3944752
	speed: 0.1628s/iter; left time: 196.3696s
	iters: 200, epoch: 6 | loss: 0.4247474
	speed: 0.0600s/iter; left time: 66.3398s
Epoch: 6 cost time: 17.697699785232544
Epoch: 6, Steps: 261 | Train Loss: 0.4170595 Vali Loss: 1.0128716 Test Loss: 0.4451327
Validation loss decreased (1.014296 --> 1.012872).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.4454320
	speed: 0.1642s/iter; left time: 155.1982s
	iters: 200, epoch: 7 | loss: 0.3689765
	speed: 0.0589s/iter; left time: 49.7950s
Epoch: 7 cost time: 16.910279512405396
Epoch: 7, Steps: 261 | Train Loss: 0.4161053 Vali Loss: 1.0128250 Test Loss: 0.4451036
Validation loss decreased (1.012872 --> 1.012825).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.4041468
	speed: 0.1617s/iter; left time: 110.6141s
	iters: 200, epoch: 8 | loss: 0.4388036
	speed: 0.0623s/iter; left time: 36.3797s
Epoch: 8 cost time: 17.882519960403442
Epoch: 8, Steps: 261 | Train Loss: 0.4153576 Vali Loss: 1.0126094 Test Loss: 0.4451420
Validation loss decreased (1.012825 --> 1.012609).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.4068907
	speed: 0.1666s/iter; left time: 70.4819s
	iters: 200, epoch: 9 | loss: 0.4190051
	speed: 0.0592s/iter; left time: 19.1145s
Epoch: 9 cost time: 17.157232522964478
Epoch: 9, Steps: 261 | Train Loss: 0.4149438 Vali Loss: 1.0124574 Test Loss: 0.4452951
Validation loss decreased (1.012609 --> 1.012457).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.3726526
	speed: 0.1616s/iter; left time: 26.1797s
	iters: 200, epoch: 10 | loss: 0.4090267
	speed: 0.0604s/iter; left time: 3.7436s
Epoch: 10 cost time: 17.45887851715088
Epoch: 10, Steps: 261 | Train Loss: 0.4149097 Vali Loss: 1.0121348 Test Loss: 0.4452943
Validation loss decreased (1.012457 --> 1.012135).  Saving model ...
Updating learning rate to 1.953125e-07
>>>>>>>testing : ETTh1_96_192_MSGNet_ETTh1_ftM_sl96_ll48_pl192_dm32_nh8_el1_dl1_df64_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
preds_shape: (84, 32, 192, 7)
trues_shape: (84, 32, 192, 7)
nd:0.5594106912612915, nrmse:0.8361493945121765, mse:0.4452943801879883, mae:0.44644758105278015, rse:0.6336877346038818, mape:10.921607971191406
time: 238.49487400054932
